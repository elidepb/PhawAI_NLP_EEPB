# üìò An√°lisis de Clasificaci√≥n de Emociones en Tweets en Espa√±ol

---

## üìå √çndice del Notebook

1. [Introducci√≥n y Objetivos](#libro-introducci√≥n)
2. [Configuraci√≥n Inicial y Librer√≠as](#libro-configuraci√≥n)
3. [Carga y Exploraci√≥n del Dataset](#libro-dataset)
4. [Preprocesamiento de Texto](#libro-preprocesamiento)
5. [Modelo 1: BiLSTM + Atenci√≥n + Caracter√≠sticas Adicionales](#lapiz-modelo-1)
6. [Modelo 2: Fine-tuning de DeBERTa-v3](#lapiz-modelo-2)
7. [Modelo 3: Instruction-Tuning con Flan-T5](#lapiz-modelo-3)
8. [Evaluaci√≥n y Comparativa de Modelos](#libro-evaluaci√≥n)
9. [Conclusiones y Recomendaciones](#libro-conclusiones)

---

## üìñ Introducci√≥n

Este notebook tiene como objetivo clasificar emociones en tweets en espa√±ol utilizando tres modelos diferentes:

1. **BiLSTM con Atenci√≥n y Caracter√≠sticas Adicionales**
2. **DeBERTa-v3 con Fine-tuning**
3. **Flan-T5 con Instruction-Tuning**

Cada modelo aborda el problema desde una perspectiva arquitect√≥nica y t√©cnica distinta, permitiendo una comparaci√≥n exhaustiva del rendimiento.

---

## üßÆ Configuraci√≥n Inicial

Se utilizan librer√≠as como:
- `pandas`, `numpy` para manipulaci√≥n de datos
- `matplotlib`, `seaborn` para visualizaci√≥n
- `nltk` para preprocesamiento de texto
- `tensorflow` y `transformers` para modelado
- `scikit-learn` para m√©tricas y validaci√≥n

---

## üìä Dataset: EmoEvent

- Dataset en espa√±ol con tweets etiquetados con emociones.
- Contiene 8,193 tweets despu√©s de la limpieza.
- 7 emociones: `anger`, `disgust`, `fear`, `joy`, `others`, `sadness`, `surprise`.
- Incluye informaci√≥n adicional como evento y si es ofensivo.

---

## üõ† Preprocesamiento de Texto

- Limpieza de URLs, menciones, hashtags, puntuaci√≥n y n√∫meros.
- Tokenizaci√≥n y eliminaci√≥n de stopwords (excepto negaciones).
- Longitud m√°xima de secuencia: 50 tokens (95% de los tweets tienen ‚â§44 palabras).

---

## ‚úèÔ∏è Modelo 1: BiLSTM + Atenci√≥n + Caracter√≠sticas Adicionales

### üß† T√©cnicas Utilizadas:
- **Embeddings FastText** preentrenados en espa√±ol (300 dimensiones).
- **Capa Bidirectional LSTM** para capturar contexto bidirectional.
- **Mecanismo de Atenci√≥n** para enfocarse en palabras relevantes.
- **Caracter√≠sticas adicionales**: evento y si es ofensivo (one-hot encoding).
- **Pesos de clase** para manejar desbalanceo.
- **P√©rdida Focal** para enfocarse en ejemplos dif√≠ciles.
- **Validaci√≥n cruzada estratificada** (5 folds).

---

## ‚úèÔ∏è Modelo 2: Fine-tuning de DeBERTa-v3

### üß† T√©cnicas Utilizadas:
- Modelo preentrenado `microsoft/deberta-v3-base`.
- Tokenizaci√≥n con m√°ximo de 50 tokens.
- Fine-tuning con 4 √©pocas, learning rate 2e-5.
- Batch size reducido (16) y gradient accumulation (4) por limitaciones de memoria.
- M√©tricas: F1, precisi√≥n, recall ponderados.
  
---

## ‚úèÔ∏è Modelo 3: Instruction-Tuning con Flan-T5

### üß† T√©cnicas Utilizadas:
- Modelo `google/flan-t5-base`.
- Formato instruccional: `"Clasificar emoci√≥n: [texto] | opciones: ..."`
- Tokenizaci√≥n separada de entrada y salida.
- Entrenamiento con 4 √©pocas, learning rate 3e-5.
- Decodificaci√≥n con beam search (4 beams).

---

## üìö Recomendaciones

- Utilizar aumentaci√≥n de datos para clases minoritarias.
- Explorar t√©cnicas de few-shot learning con LLMs.

---
